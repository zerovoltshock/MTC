{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28df5728-c8cd-4699-88ea-b3909814d48f",
   "metadata": {},
   "source": [
    "# LightGBMの学習速度\n",
    "- CPU\n",
    "```\n",
    "[LightGBM] [Info] Number of positive: 35018, number of negative: 34982\n",
    "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.366908 seconds.\n",
    "You can set `force_col_wise=true` to remove the overhead.\n",
    "[LightGBM] [Info] Total Bins 255000\n",
    "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 1000\n",
    "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500257 -> initscore=0.001029\n",
    "[LightGBM] [Info] Start training from score 0.001029\n",
    "INFO:__main__:Elapsed Time: 351.84 sec\n",
    "INFO:__main__:Validation Metric: 0.11437848050873242\n",
    "```\n",
    "\n",
    "```\n",
    "[LightGBM] [Info] Number of positive: 35018, number of negative: 34982\n",
    "[LightGBM] [Info] This is the GPU trainer!!\n",
    "[LightGBM] [Info] Total Bins 255000\n",
    "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 1000\n",
    "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
    "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 770, Vendor: Intel(R) Corporation\n",
    "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
    "[LightGBM] [Info] GPU programs have been built\n",
    "[LightGBM] [Info] Size of histogram bin entry: 8\n",
    "[LightGBM] [Info] 1000 dense feature groups (66.76 MB) transferred to GPU in 0.020182 secs. 0 sparse feature groups\n",
    "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500257 -> initscore=0.001029\n",
    "[LightGBM] [Info] Start training from score 0.001029\n",
    "INFO:__main__:Elapsed Time: 407.22 sec\n",
    "INFO:__main__:Validation Metric: 0.11342810052390678\n",
    "```\n",
    "\n",
    "- GPU\n",
    "```\n",
    "[LightGBM] [Info] Number of positive: 35018, number of negative: 34982\n",
    "[LightGBM] [Info] This is the GPU trainer!!\n",
    "[LightGBM] [Info] Total Bins 255000\n",
    "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 1000\n",
    "[LightGBM] [Info] Using requested OpenCL platform 1 device 0\n",
    "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
    "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
    "[LightGBM] [Info] GPU programs have been built\n",
    "[LightGBM] [Info] Size of histogram bin entry: 8\n",
    "[LightGBM] [Info] 1000 dense feature groups (66.76 MB) transferred to GPU in 0.024623 secs. 0 sparse feature groups\n",
    "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500257 -> initscore=0.001029\n",
    "[LightGBM] [Info] Start training from score 0.001029\n",
    "INFO:__main__:Elapsed Time: 250.90 sec\n",
    "INFO:__main__:Validation Metric: 0.11437778313272819\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b909466",
   "metadata": {},
   "source": [
    "- CatBoost(GPU)\n",
    "```\n",
    "INFO:__main__:Elapsed Time: 57.76 sec\n",
    "4999:\tlearn: 0.0580361\ttest: 0.0991410\tbest: 0.0991401 (4998)\ttotal: 55.2s\tremaining: 0us\n",
    "bestTest = 0.09914007161\n",
    "bestIteration = 4998\n",
    "INFO:__main__:Validation Metric: 0.09914105790309861\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0985fd-2c86-4e38-9c60-41f3e970e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcef29dd-56bc-4880-bafb-8b088c74d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cpuでの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d83ba85-48dd-4fb1-bdc2-097dd6bbe950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 35018, number of negative: 34982\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.366908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 1000\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500257 -> initscore=0.001029\n",
      "[LightGBM] [Info] Start training from score 0.001029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Elapsed Time: 351.84 sec\n",
      "INFO:__main__:Validation Metric: 0.11437848050873242\n"
     ]
    }
   ],
   "source": [
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timeit():\n",
    "    \"\"\"処理にかかった時間を計測してログに出力するコンテキストマネージャ\"\"\"\n",
    "    start = time.time()\n",
    "    yield\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    LOGGER.info(f'Elapsed Time: {elapsed:.2f} sec')\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        stream=sys.stderr,\n",
    "                        )\n",
    "\n",
    "    # 疑似的な教師信号を作るためのパラメータ\n",
    "    dist_args = {\n",
    "        # データ点数\n",
    "        'n_samples': 100_000,\n",
    "        # 次元数\n",
    "        'n_features': 1_000,\n",
    "        # その中で意味のあるもの\n",
    "        'n_informative': 100,\n",
    "        # 重複や繰り返しはなし\n",
    "        'n_redundant': 0,\n",
    "        'n_repeated': 0,\n",
    "        # タスクの難易度\n",
    "        'class_sep': 0.65,\n",
    "        # 二値分類問題\n",
    "        'n_classes': 2,\n",
    "        # 生成に用いる乱数\n",
    "        'random_state': 42,\n",
    "        # 特徴の順序をシャッフルしない (先頭の次元が informative になる)\n",
    "        'shuffle': False,\n",
    "    }\n",
    "    # 教師データを作る\n",
    "    train_x, train_y = make_classification(**dist_args)\n",
    "    # データセットを学習用と検証用に分割する\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y,\n",
    "                                                test_size=0.3,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=42,\n",
    "                                                stratify=train_y)\n",
    "    # CatBoost が扱うデータセットの形式に直す\n",
    "    train_pool = lgb.Dataset(x_tr, label=y_tr)\n",
    "    valid_pool = lgb.Dataset(x_val, label=y_val)\n",
    "    # 学習用のパラメータ\n",
    "    params = {\n",
    "        # タスク設定と損失関数\n",
    "        'objective': 'binary',\n",
    "        # 学習率\n",
    "        'learning_rate': 0.02,\n",
    "        # 学習ラウンド数\n",
    "        'num_boost_round': 5_000,\n",
    "        # 検証用データの損失が既定ラウンド数減らなかったら学習を打ち切る\n",
    "        # NOTE: ラウンド数を揃えたいので今回は使わない\n",
    "        # 'early_stopping_rounds': 100,\n",
    "        # 乱数シード\n",
    "        'random_state': 42,\n",
    "        # 学習に GPU を使う場合\n",
    "        # 'device': 'gpu',\n",
    "    }\n",
    "    # モデルを学習する\n",
    "    with timeit():\n",
    "        model = lgb.train(params, \n",
    "                          train_pool,\n",
    "                          valid_sets=[valid_pool]\n",
    "                          )\n",
    "\n",
    "    # 検証用データを分類する\n",
    "    y_pred = model.predict(x_val)\n",
    "    # ロジスティック損失を確認する\n",
    "    metric = log_loss(y_val, y_pred)\n",
    "    LOGGER.info(f'Validation Metric: {metric}')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87b2e72-d786-4055-a167-f06c1b8c8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPUの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ac39d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 35018, number of negative: 34982\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 1000\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics 770, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1000 dense feature groups (66.76 MB) transferred to GPU in 0.020182 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500257 -> initscore=0.001029\n",
      "[LightGBM] [Info] Start training from score 0.001029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Elapsed Time: 407.22 sec\n",
      "INFO:__main__:Validation Metric: 0.11342810052390678\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timeit():\n",
    "    \"\"\"処理にかかった時間を計測してログに出力するコンテキストマネージャ\"\"\"\n",
    "    start = time.time()\n",
    "    yield\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    LOGGER.info(f'Elapsed Time: {elapsed:.2f} sec')\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        stream=sys.stderr,\n",
    "                        )\n",
    "\n",
    "    # 疑似的な教師信号を作るためのパラメータ\n",
    "    dist_args = {\n",
    "        # データ点数\n",
    "        'n_samples': 100_000,\n",
    "        # 次元数\n",
    "        'n_features': 1_000,\n",
    "        # その中で意味のあるもの\n",
    "        'n_informative': 100,\n",
    "        # 重複や繰り返しはなし\n",
    "        'n_redundant': 0,\n",
    "        'n_repeated': 0,\n",
    "        # タスクの難易度\n",
    "        'class_sep': 0.65,\n",
    "        # 二値分類問題\n",
    "        'n_classes': 2,\n",
    "        # 生成に用いる乱数\n",
    "        'random_state': 42,\n",
    "        # 特徴の順序をシャッフルしない (先頭の次元が informative になる)\n",
    "        'shuffle': False,\n",
    "    }\n",
    "    # 教師データを作る\n",
    "    train_x, train_y = make_classification(**dist_args)\n",
    "    # データセットを学習用と検証用に分割する\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y,\n",
    "                                                test_size=0.3,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=42,\n",
    "                                                stratify=train_y)\n",
    "    # CatBoost が扱うデータセットの形式に直す\n",
    "    train_pool = lgb.Dataset(x_tr, label=y_tr)\n",
    "    valid_pool = lgb.Dataset(x_val, label=y_val)\n",
    "    # 学習用のパラメータ\n",
    "    params = {\n",
    "        # タスク設定と損失関数\n",
    "        'objective': 'binary',\n",
    "        # 学習率\n",
    "        'learning_rate': 0.02,\n",
    "        # 学習ラウンド数\n",
    "        'num_boost_round': 5_000,\n",
    "        # 検証用データの損失が既定ラウンド数減らなかったら学習を打ち切る\n",
    "        # NOTE: ラウンド数を揃えたいので今回は使わない\n",
    "        # 'early_stopping_rounds': 100,\n",
    "        # 乱数シード\n",
    "        'random_state': 42,\n",
    "        # 学習に GPU を使う場合\n",
    "        'device': 'gpu',\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "    }\n",
    "    # モデルを学習する\n",
    "    #model = lgb.train(params, train_pool,valid_sets=[valid_pool])\n",
    "    with timeit():\n",
    "        model = lgb.train(params, \n",
    "                          train_pool,\n",
    "                          valid_sets=[valid_pool], \n",
    "                          # verbose_eval=100\n",
    "                          )\n",
    "    model.save_model('model_gpu.txt'\n",
    "                     #, num_iteration=model.best_iteration\n",
    "                     )\n",
    "        #model.fit(train_pool,\n",
    "        #          eval_set=valid_pool,\n",
    "        #          verbose_eval=100,\n",
    "        #          use_best_model=True,\n",
    "        #          )\n",
    "    # 検証用データを分類する\n",
    "    y_pred = model.predict(x_val)\n",
    "    # ロジスティック損失を確認する\n",
    "    metric = log_loss(y_val, y_pred)\n",
    "    LOGGER.info(f'Validation Metric: {metric}')\n",
    "\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00812d0a-6c9f-4173-9e79-7c1e3c157b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 35018, number of negative: 34982\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 255000\n",
      "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 1000\n",
      "[LightGBM] [Info] Using requested OpenCL platform 1 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 1000 dense feature groups (66.76 MB) transferred to GPU in 0.024623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500257 -> initscore=0.001029\n",
      "[LightGBM] [Info] Start training from score 0.001029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Elapsed Time: 250.90 sec\n",
      "INFO:__main__:Validation Metric: 0.11437778313272819\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timeit():\n",
    "    \"\"\"処理にかかった時間を計測してログに出力するコンテキストマネージャ\"\"\"\n",
    "    start = time.time()\n",
    "    yield\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    LOGGER.info(f'Elapsed Time: {elapsed:.2f} sec')\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        stream=sys.stderr,\n",
    "                        )\n",
    "\n",
    "    # 疑似的な教師信号を作るためのパラメータ\n",
    "    dist_args = {\n",
    "        # データ点数\n",
    "        'n_samples': 100_000,\n",
    "        # 次元数\n",
    "        'n_features': 1_000,\n",
    "        # その中で意味のあるもの\n",
    "        'n_informative': 100,\n",
    "        # 重複や繰り返しはなし\n",
    "        'n_redundant': 0,\n",
    "        'n_repeated': 0,\n",
    "        # タスクの難易度\n",
    "        'class_sep': 0.65,\n",
    "        # 二値分類問題\n",
    "        'n_classes': 2,\n",
    "        # 生成に用いる乱数\n",
    "        'random_state': 42,\n",
    "        # 特徴の順序をシャッフルしない (先頭の次元が informative になる)\n",
    "        'shuffle': False,\n",
    "    }\n",
    "    # 教師データを作る\n",
    "    train_x, train_y = make_classification(**dist_args)\n",
    "    # データセットを学習用と検証用に分割する\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y,\n",
    "                                                test_size=0.3,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=42,\n",
    "                                                stratify=train_y)\n",
    "    # CatBoost が扱うデータセットの形式に直す\n",
    "    train_pool = lgb.Dataset(x_tr, label=y_tr)\n",
    "    valid_pool = lgb.Dataset(x_val, label=y_val)\n",
    "    # 学習用のパラメータ\n",
    "    params = {\n",
    "        # タスク設定と損失関数\n",
    "        'objective': 'binary',\n",
    "        # 学習率\n",
    "        'learning_rate': 0.02,\n",
    "        # 学習ラウンド数\n",
    "        'num_boost_round': 5_000,\n",
    "        # 検証用データの損失が既定ラウンド数減らなかったら学習を打ち切る\n",
    "        # NOTE: ラウンド数を揃えたいので今回は使わない\n",
    "        # 'early_stopping_rounds': 100,\n",
    "        # 乱数シード\n",
    "        'random_state': 42,\n",
    "        # 学習に GPU を使う場合\n",
    "        'device': 'gpu',\n",
    "        'gpu_platform_id': 1,\n",
    "        'gpu_device_id': 0,\n",
    "    }\n",
    "    # モデルを学習する\n",
    "    #model = lgb.train(params, train_pool,valid_sets=[valid_pool])\n",
    "    with timeit():\n",
    "        model = lgb.train(params, \n",
    "                          train_pool,\n",
    "                          valid_sets=[valid_pool], \n",
    "                          # verbose_eval=100\n",
    "                          )\n",
    "    model.save_model('model_gpu.txt'\n",
    "                     #, num_iteration=model.best_iteration\n",
    "                     )\n",
    "        #model.fit(train_pool,\n",
    "        #          eval_set=valid_pool,\n",
    "        #          verbose_eval=100,\n",
    "        #          use_best_model=True,\n",
    "        #          )\n",
    "    # 検証用データを分類する\n",
    "    y_pred = model.predict(x_val)\n",
    "    # ロジスティック損失を確認する\n",
    "    metric = log_loss(y_val, y_pred)\n",
    "    LOGGER.info(f'Validation Metric: {metric}')\n",
    "\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd15e52",
   "metadata": {},
   "source": [
    "## catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4410aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6917632\ttest: 0.6918459\tbest: 0.6918459 (0)\ttotal: 25.7ms\tremaining: 2m 8s\n",
      "100:\tlearn: 0.5876281\ttest: 0.5928320\tbest: 0.5928320 (100)\ttotal: 1.19s\tremaining: 57.7s\n",
      "200:\tlearn: 0.5150117\ttest: 0.5240579\tbest: 0.5240579 (200)\ttotal: 2.33s\tremaining: 55.5s\n",
      "300:\tlearn: 0.4590706\ttest: 0.4709485\tbest: 0.4709485 (300)\ttotal: 3.48s\tremaining: 54.4s\n",
      "400:\tlearn: 0.4139224\ttest: 0.4279887\tbest: 0.4279887 (400)\ttotal: 4.62s\tremaining: 53s\n",
      "500:\tlearn: 0.3767624\ttest: 0.3929598\tbest: 0.3929598 (500)\ttotal: 5.76s\tremaining: 51.7s\n",
      "600:\tlearn: 0.3452963\ttest: 0.3632068\tbest: 0.3632068 (600)\ttotal: 6.94s\tremaining: 50.8s\n",
      "700:\tlearn: 0.3171706\ttest: 0.3365992\tbest: 0.3365992 (700)\ttotal: 8.13s\tremaining: 49.8s\n",
      "800:\tlearn: 0.2929540\ttest: 0.3137095\tbest: 0.3137095 (800)\ttotal: 9.26s\tremaining: 48.6s\n",
      "900:\tlearn: 0.2717450\ttest: 0.2937264\tbest: 0.2937264 (900)\ttotal: 10.4s\tremaining: 47.4s\n",
      "1000:\tlearn: 0.2528601\ttest: 0.2759136\tbest: 0.2759136 (1000)\ttotal: 11.6s\tremaining: 46.2s\n",
      "1100:\tlearn: 0.2365481\ttest: 0.2605303\tbest: 0.2605303 (1100)\ttotal: 12.7s\tremaining: 45s\n",
      "1200:\tlearn: 0.2217217\ttest: 0.2464831\tbest: 0.2464831 (1200)\ttotal: 13.9s\tremaining: 43.9s\n",
      "1300:\tlearn: 0.2084510\ttest: 0.2339263\tbest: 0.2339263 (1300)\ttotal: 15s\tremaining: 42.8s\n",
      "1400:\tlearn: 0.1963303\ttest: 0.2225263\tbest: 0.2225263 (1400)\ttotal: 16.2s\tremaining: 41.5s\n",
      "1500:\tlearn: 0.1854035\ttest: 0.2122024\tbest: 0.2122024 (1500)\ttotal: 17.3s\tremaining: 40.3s\n",
      "1600:\tlearn: 0.1753169\ttest: 0.2026845\tbest: 0.2026845 (1600)\ttotal: 18.4s\tremaining: 39.1s\n",
      "1700:\tlearn: 0.1661259\ttest: 0.1939569\tbest: 0.1939569 (1700)\ttotal: 19.5s\tremaining: 37.9s\n",
      "1800:\tlearn: 0.1576360\ttest: 0.1859924\tbest: 0.1859924 (1800)\ttotal: 20.6s\tremaining: 36.6s\n",
      "1900:\tlearn: 0.1498323\ttest: 0.1786239\tbest: 0.1786239 (1900)\ttotal: 21.7s\tremaining: 35.4s\n",
      "2000:\tlearn: 0.1425373\ttest: 0.1716733\tbest: 0.1716733 (2000)\ttotal: 22.8s\tremaining: 34.2s\n",
      "2100:\tlearn: 0.1357439\ttest: 0.1652680\tbest: 0.1652680 (2100)\ttotal: 24s\tremaining: 33.1s\n",
      "2200:\tlearn: 0.1294341\ttest: 0.1593760\tbest: 0.1593760 (2200)\ttotal: 25.1s\tremaining: 31.9s\n",
      "2300:\tlearn: 0.1235589\ttest: 0.1539434\tbest: 0.1539434 (2300)\ttotal: 26.2s\tremaining: 30.7s\n",
      "2400:\tlearn: 0.1183041\ttest: 0.1490450\tbest: 0.1490450 (2400)\ttotal: 27.3s\tremaining: 29.5s\n",
      "2500:\tlearn: 0.1134267\ttest: 0.1444992\tbest: 0.1444992 (2500)\ttotal: 28.3s\tremaining: 28.3s\n",
      "2600:\tlearn: 0.1089676\ttest: 0.1404272\tbest: 0.1404272 (2600)\ttotal: 29.5s\tremaining: 27.2s\n",
      "2700:\tlearn: 0.1048598\ttest: 0.1367313\tbest: 0.1367313 (2700)\ttotal: 30.6s\tremaining: 26s\n",
      "2800:\tlearn: 0.1011592\ttest: 0.1334773\tbest: 0.1334773 (2800)\ttotal: 31.7s\tremaining: 24.9s\n",
      "2900:\tlearn: 0.0977983\ttest: 0.1305922\tbest: 0.1305922 (2900)\ttotal: 32.8s\tremaining: 23.7s\n",
      "3000:\tlearn: 0.0947583\ttest: 0.1280795\tbest: 0.1280795 (3000)\ttotal: 33.9s\tremaining: 22.6s\n",
      "3100:\tlearn: 0.0918051\ttest: 0.1255369\tbest: 0.1255369 (3100)\ttotal: 35s\tremaining: 21.4s\n",
      "3200:\tlearn: 0.0891061\ttest: 0.1232841\tbest: 0.1232841 (3200)\ttotal: 36.1s\tremaining: 20.3s\n",
      "3300:\tlearn: 0.0864773\ttest: 0.1210574\tbest: 0.1210574 (3300)\ttotal: 37.2s\tremaining: 19.1s\n",
      "3400:\tlearn: 0.0841664\ttest: 0.1192489\tbest: 0.1192489 (3400)\ttotal: 38.2s\tremaining: 18s\n",
      "3500:\tlearn: 0.0819173\ttest: 0.1174105\tbest: 0.1174105 (3500)\ttotal: 39.3s\tremaining: 16.8s\n",
      "3600:\tlearn: 0.0798013\ttest: 0.1156967\tbest: 0.1156967 (3600)\ttotal: 40.4s\tremaining: 15.7s\n",
      "3700:\tlearn: 0.0779157\ttest: 0.1142577\tbest: 0.1142577 (3700)\ttotal: 41.4s\tremaining: 14.5s\n",
      "3800:\tlearn: 0.0759998\ttest: 0.1127695\tbest: 0.1127695 (3800)\ttotal: 42.5s\tremaining: 13.4s\n",
      "3900:\tlearn: 0.0742205\ttest: 0.1113850\tbest: 0.1113837 (3899)\ttotal: 43.5s\tremaining: 12.3s\n",
      "4000:\tlearn: 0.0725772\ttest: 0.1101694\tbest: 0.1101694 (4000)\ttotal: 44.6s\tremaining: 11.1s\n",
      "4100:\tlearn: 0.0708309\ttest: 0.1088060\tbest: 0.1088045 (4099)\ttotal: 45.6s\tremaining: 10s\n",
      "4200:\tlearn: 0.0691808\ttest: 0.1075259\tbest: 0.1075253 (4199)\ttotal: 46.7s\tremaining: 8.88s\n",
      "4300:\tlearn: 0.0676999\ttest: 0.1064139\tbest: 0.1064136 (4299)\ttotal: 47.7s\tremaining: 7.76s\n",
      "4400:\tlearn: 0.0662291\ttest: 0.1053384\tbest: 0.1053375 (4398)\ttotal: 48.8s\tremaining: 6.64s\n",
      "4500:\tlearn: 0.0647721\ttest: 0.1042589\tbest: 0.1042570 (4498)\ttotal: 49.9s\tremaining: 5.53s\n",
      "4600:\tlearn: 0.0632834\ttest: 0.1031118\tbest: 0.1031116 (4599)\ttotal: 50.9s\tremaining: 4.42s\n",
      "4700:\tlearn: 0.0619935\ttest: 0.1021598\tbest: 0.1021598 (4700)\ttotal: 52s\tremaining: 3.31s\n",
      "4800:\tlearn: 0.0606558\ttest: 0.1011736\tbest: 0.1011736 (4800)\ttotal: 53.2s\tremaining: 2.2s\n",
      "4900:\tlearn: 0.0592802\ttest: 0.1000982\tbest: 0.1000970 (4899)\ttotal: 54.2s\tremaining: 1.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Elapsed Time: 57.76 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999:\tlearn: 0.0580361\ttest: 0.0991410\tbest: 0.0991401 (4998)\ttotal: 55.2s\tremaining: 0us\n",
      "bestTest = 0.09914007161\n",
      "bestIteration = 4998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Validation Metric: 0.09914105790309861\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "@contextmanager\n",
    "def timeit():\n",
    "    \"\"\"処理にかかった時間を計測してログに出力するコンテキストマネージャ\"\"\"\n",
    "    start = time.time()\n",
    "    yield\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    LOGGER.info(f'Elapsed Time: {elapsed:.2f} sec')\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                      stream=sys.stderr,\n",
    "                      )\n",
    "\n",
    "    # 疑似的な教師信号を作るためのパラメータ\n",
    "    dist_args = {\n",
    "        # データ点数\n",
    "        'n_samples': 100_000,\n",
    "        # 次元数\n",
    "        'n_features': 1_000,\n",
    "        # その中で意味のあるもの\n",
    "        'n_informative': 100,\n",
    "        # 重複や繰り返しはなし\n",
    "        'n_redundant': 0,\n",
    "        'n_repeated': 0,\n",
    "        # タスクの難易度\n",
    "        'class_sep': 0.65,\n",
    "        # 二値分類問題\n",
    "        'n_classes': 2,\n",
    "        # 生成に用いる乱数\n",
    "        'random_state': 42,\n",
    "        # 特徴の順序をシャッフルしない (先頭の次元が informative になる)\n",
    "        'shuffle': False,\n",
    "    }\n",
    "    # 教師データを作る\n",
    "    train_x, train_y = make_classification(**dist_args)\n",
    "    # データセットを学習用と検証用に分割する\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(train_x, train_y,\n",
    "                                              test_size=0.3,\n",
    "                                              shuffle=True,\n",
    "                                              random_state=42,\n",
    "                                              stratify=train_y)\n",
    "    \n",
    "    # CatBoost用のデータプール作成\n",
    "    train_pool = Pool(x_tr, label=y_tr)\n",
    "    valid_pool = Pool(x_val, label=y_val)\n",
    "\n",
    "    # 学習用のパラメータ\n",
    "    params = {\n",
    "        # タスク設定と損失関数\n",
    "        'loss_function': 'Logloss',\n",
    "        # 学習率\n",
    "        'learning_rate': 0.02,\n",
    "        # 学習ラウンド数\n",
    "        'iterations': 5_000,\n",
    "        # 乱数シード\n",
    "        'random_seed': 42,\n",
    "        # 評価指標\n",
    "        'eval_metric': 'Logloss',\n",
    "        # GPU設定\n",
    "        'task_type': 'GPU',\n",
    "        'devices': '0:1',  # GPUデバイス指定 (プラットフォーム1、デバイス0)\n",
    "        # その他最適化設定\n",
    "        'bootstrap_type': 'Bernoulli',\n",
    "        'subsample': 0.8,\n",
    "        'depth': 6,\n",
    "        'l2_leaf_reg': 3.0,\n",
    "        'verbose': 100  # 100イテレーションごとに進捗表示\n",
    "    }\n",
    "\n",
    "    # モデルを学習する\n",
    "    with timeit():\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool,\n",
    "                 eval_set=valid_pool,\n",
    "                 use_best_model=False)  # early_stoppingを使わない設定\n",
    "\n",
    "    # モデルを保存\n",
    "    model.save_model('model_gpu.cbm')\n",
    "\n",
    "    # 検証用データを分類する\n",
    "    y_pred = model.predict_proba(x_val)[:, 1]  # クラス1の確率を取得\n",
    "    # ロジスティック損失を確認する\n",
    "    metric = log_loss(y_val, y_pred)\n",
    "    LOGGER.info(f'Validation Metric: {metric}')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f5318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3a5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a5ba81d",
   "metadata": {},
   "source": [
    "## OpenCLの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f2e3b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4ae269-5668-4f0f-97f1-98bd6116322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform ID: 0, Name: Intel(R) OpenCL Graphics\n",
      "  Device ID: 0, Name: Intel(R) UHD Graphics 770, Type: ALL | GPU\n",
      "Platform ID: 1, Name: NVIDIA CUDA\n",
      "  Device ID: 0, Name: NVIDIA GeForce RTX 3090, Type: ALL | GPU\n"
     ]
    }
   ],
   "source": [
    "import pyopencl as cl\n",
    "\n",
    "# 全てのプラットフォームを取得\n",
    "platforms = cl.get_platforms()\n",
    "\n",
    "# 各プラットフォームの詳細を表示\n",
    "for platform_id, platform in enumerate(platforms):\n",
    "    print(f\"Platform ID: {platform_id}, Name: {platform.name}\")\n",
    "    # 各プラットフォーム内のデバイスを取得\n",
    "    devices = platform.get_devices()\n",
    "    for device_id, device in enumerate(devices):\n",
    "        print(f\"  Device ID: {device_id}, Name: {device.name}, Type: {cl.device_type.to_string(device.type)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7605e42c-0122-4fe5-8d14-617a0f9e3875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyopencl.Device 'NVIDIA GeForce RTX 3090' on 'NVIDIA CUDA' at 0x226a9ab0280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd77ca-88c2-4d40-8e48-a7491060eaed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
